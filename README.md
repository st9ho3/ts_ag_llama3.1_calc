README_CONTENT="Weather & Calculation AI Assistant\n\nThis project is an AI assistant built to provide practical weather advice and perform numerical calculations based on user prompts. It integrates with external APIs for real-time weather data and leverages local or cloud-based language models to process queries. The assistant can answer questions like \"Should I take a jacket to LA?\" or \"What’s the sum of 5 and 10?\" with clear, human-friendly responses.\n\n## Features\n\n1. **Weather Assistance**:\n   - Normalizes abbreviated city names (e.g., \"LA\" to \"Los Angeles\").\n   - Fetches real-time weather data using the OpenWeatherMap API.\n   - Provides actionable advice (e.g., \"Take a jacket if it’s chilly!\").\n\n2. **Numerical Calculations**:\n   - Supports basic arithmetic operations: addition, subtraction, multiplication, and division.\n   - Uses dedicated tools to ensure precise calculations with numerical inputs only.\n\n3. **Dual Model Support**:\n   - **Google Gemini**: Connects to the `gemini-2.0-flash` model via API for weather-related queries.\n   - **Ollama with Llama 3.1**: Runs locally using the `llama3.1:latest` model for both weather and calculation tasks.\n\n4. **Tool Integration**:\n   - Custom tools for calculations and weather retrieval, defined with schemas using `zod`.\n   - Extensible architecture for adding more tools.\n\n## Prerequisites\n\n- **Node.js**: Version 18.x or higher.\n- **npm**: For package management.\n- **dotenv**: To manage environment variables (e.g., API keys).\n- **OpenWeatherMap API Key**: Required for weather data. Sign up [here](https://openweathermap.org/api) to get one.\n- **Ollama**: For local model execution (optional, see below).\n\n## Installation\n\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/your-username/your-repo-name.git\n   cd your-repo-name\n   ```\n\n2. **Install Dependencies**:\n   ```bash\n   npm install\n   ```\n   This installs required packages, including:\n   - `@google/generative-ai`\n   - `@langchain/ollama`\n   - `@langchain/core`\n   - `zod`\n   - `dotenv`\n\n3. **Set Up Environment Variables**:\n   Create a `.env` file in the root directory and add the following:\n   ```env\n   LLM_API=your-google-generative-ai-key  # Optional, for Google Gemini\n   API_KEY=your-openweathermap-api-key    # Required for weather data\n   ```\n   - Replace `your-google-generative-ai-key` with your Google Generative AI API key (if using Gemini).\n   - Replace `your-openweathermap-api-key` with your OpenWeatherMap API key.\n\n4. **Install Ollama (For Local Model)**:\n   - Download and install Ollama from [ollama.ai](https://ollama.ai/).\n   - Pull the `llama3.1:latest` model:\n     ```bash\n     ollama pull llama3.1:latest\n     ```\n   - Start the Ollama server:\n     ```bash\n     ollama serve\n     ```\n     Ensure it runs on `http://localhost:11434` (default).\n\n## Usage\n\n### Running with Google Gemini\nEdit the prompt in `calGemini.ts` to test different queries (e.g., \"Should I wear shorts in Seattle?\"). Then run:\n```bash\nnpx ts-node calGemini.ts\n```\nRequires `LLM_API` in `.env`.\n\n### Running with Ollama (Local)\nEdit the prompt in `callLLM.ts` (e.g., \"Should I take a jacket to LA?\"). Then run:\n```bash\nnpx ts-node callLLM.ts\n```\nRequires Ollama running locally with `llama3.1:latest`.\n\n### Example Outputs\n- **Weather Query**: \"Should I take a jacket to LA?\"\n  - Response: \"In Los Angeles, it’s warm today, so you might not need a jacket—just a light layer should do!\"\n- **Calculation Query**: \"What’s 5 plus 10?\"\n  - Response: \"The sum of 5 and 10 is 15.\"\n\n## Project Structure\n\n- **`calGemini.ts`**: Handles weather queries using Google Gemini.\n- **`callLLM.ts`**: Manages both weather and calculation queries using Ollama locally.\n- **`tools.ts`**: Defines calculation and weather tools with `zod` schemas.\n- **`api.ts`**: Implements the weather API call to OpenWeatherMap.\n- **`messages.ts`**: Contains system prompts for weather and calculation logic.\n\n## Extending the Assistant\n\n- **Add New Tools**: Define new functions in `tools.ts` and register them in the `tools` array.\n- **Custom Prompts**: Modify `messages.ts` to tweak the assistant’s behavior or tone.\n\n## Limitations\n\n- Requires an internet connection for weather data and Google Gemini.\n- Local Ollama execution depends on sufficient hardware (e.g., RAM for `llama3.1`).\n- Error handling assumes undefined responses are gracefully managed.\n\n## Contributing\n\nFeel free to submit issues or pull requests to enhance functionality, fix bugs, or improve documentation.\n\n## License\n\nMIT License. See [LICENSE](LICENSE) for details."
